- var base = '/assets/pub/design-ethics-no-thanks'

input(type="checkbox")#toggleFootnotes
article.lyt-article

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p #[em Will Design Ethics save design]? As the broader design community and the public becomes increasingly uncomfortable with the structures and clients it serves, a growing movement seeks to integrate ethics into design practice. But this prioritises individual decisions and values over critical analysis of socio-political and economic outcomes. The pop discourse that calls for ethics indemnifies designers and obfuscates the inherent problems of their work, resulting in the celebration of projects that at their core problematic, such as digital wellness, decentralised systems, autonomous cars and inclusive facial recognition. This essay details how design has enabled a decade of absurdity and examine how design ethics threatens to neutralise both the critique of outcomes and the potential contribution of design to a radically reimagined world."

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p In 2017 at an event held by the Stanford Business School, former Facebook exec Chamath Palihapitiya made international headlines by expressing a seemingly rare and frank level of remorse at his role in building Facebook. His central belief is stark: through a mix of good intentions and feelings of trepidation, Facebook’s unethical design now serves as a cause of disinformation, political polarisation, and addiction.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Elsewhere, organisations like the Centre for Humane Technology argue that the ills of modern times - addiction, misinformation, polarization - are all traits of an unethical approach to designing interfaces and platforms. Using dark UX patterns, and addictive design, the tech we use causes “human downgrading,” reducing a person’s potential to be their best. At scale, the Centre of Humane Technology sees this as a technologically driven existential threat to humanity.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p These arguments share a common theme, where the decisions made when designing a system or an interface can directly cause terrible outcomes. 

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Let's look at three brief moments in time through the lens of this design ethics critique.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p In this viral video, an infant is delighted by a smartphone. When its parents take the device, the child responds with a horrendous tantrum. I’ve spared this room from the sound, but trust me, its blood curdling. You can see how loud it is in the kid’s face. This is the tragedy of innocence, where the systems we have built can reprogram you no matter your age and cause you to develop dependency on the screen, soon after you enter this world.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p This video shows the disturbingly filthy room of a teenage streamer. As she sits ignoring the cameraperson in the room with her, you can infer how much time she spends online by the items around her desk. This is the tragedy of youth, in which the systems we have built are designed to trigger addictive vanity and cause you to perform and curate yourself online.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p In this video, an older woman livestreams herself to a small audience. She’s a member of the right wing QAnon conspiracy, and she’s telling her viewers about her discovery: That McDonalds is grinding children into their food and selling them as Big Macs in restaurants across America. The people in her comments are shocked and cheering her on in a vicious feedback loop. This is the tragedy of reality, in which the systems we have built are designed to push disinformation and cause you to question the world in incoherent or conspiratorial ways.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p When Palihapitiya and Harris describe the unethical behaviour of technology builders, they are referring to outcomes like these and many more. They are members of a growing chorus of tech executives, design practitioners, academics and journalists who see these as forces that rip society apart, and that intervention can be found through the introduction of design ethics, a promising core foundation to right this crisis.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p But what if design ethics is not the answer? What if, instead, inherit to the design ethics movement, is a serious misunderstanding of the role that designed systems play in our lives. Worse, Design Ethics is a form of reductionism that allows designers to escape scrutiny of their work as it fails individuals and communities, and as we collectively grapple with the realities of broader social, technological and political realities.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Almost all popular frameworks that include design ethics consider it as practice based, a responsibility of an individual or team to assess their motivations over what they choose to build. The onus for better outcomes lies at the feet of anyone who touches a designed system or app or platform, and that they can respond with a variety of tools. I want to explore two that I think are very common. Consent and inclusion.

  .lyt-row
    .lyt.txt.mcw-reg.ma-reg
      h3 The Myth of Informed Consent

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Consent in technology is drawn from inclusive and progressive politics, setting a foundation to advocate for the empowered individual. In the interface, consent is often combined with frictionless design, empowering users through simple language and interactions.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Two popular definitions of consent comes from #[em #[label(for="toggleFootnotes") Building Consentful Tech]] by Una Lee and Dann Toliver, and the #[em #[label(for="toggleFootnotes")] Society Centered Design Principles]] by Projects By If. To quote from Building Concentful Tech, “Consent is described freely given without duress, and can be withdrawn at any time. Cultivating consent means the user must be informed and the process transparent.” Projects by If describes Design as a political act and it’s our responsibility to design for people’s rights. Privacy is not a luxury for those that can afford it. Privacy is a human right. We must create systems that remove the imbalance of power and instead promote equity and citizen empowerment.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Consent is a key framing for all designed systems, so much so that an an attempt at an ethically designed consent system even made it into the the European Union’s General Data Protection Regulation.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p But in 2017 the average smartphone user in Europe or North America had 80 apps installed on their device, each with their own important use cases, their own living terms of service, and most importantly, each interacting with broader networks of dozens, hundreds or thousands of actors. Expecting a user to maintain an informed agreement with just one wholly unknowable system is impossible. Informed consent crumbles at scale, and sits in direct conflict in a world saturated with platforms and stakeholders. I may have an agreement with Twitter, but how does this extend to algorithmic analysis of my creditworthiness now, or in the future?

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Withdrawing consent - even when seemingly informed - can also be deeply problematic. Disabling location services is withdrawing consent, but sharing your location with someone you trust while on a date is a key safety technique for vulnerable users. Location services also help users with mobility or accessibility difficulties navigate more easily. To opt out is to reduce your quality of life, or threaten your physical safety.

  .lyt-row
    .lyt.txt.mcw-reg.ma-reg
      h3 Inclusion
  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Design ethics often frames its criticism from a solutions-based representation perspective. A problematic behaviour is observed, identified as caused by technology, and a solution is sought to address it. The criticism of early facial recognition technology stands perhaps as one of the most troubling examples of popular solutionism in the last five years. In this video from 2011, a HP computer with facial recognition ignores a black man’s face, and follows his white colleague. Early biometrics, loaded with homogenous data sets were unable to detect or respond to non-white features, and popular discourse rightfully seized upon the racism embedded in these technologies.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p As a result, these technologies are more normalised and more resilient. In Seattle, shoppers can walk into Amazon store with no cashiers and no payment terminal, pick up the items they want, and leave. This is facilitated by facial recognition.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p What starts as criticism of the lack of inclusivity of a technology leads to two political worlds converging by the end of the decade, enabled but not caused by technology. The user experience of these two worlds is almost identical, but the key difference between them is power.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p It is not hard to imagine Amazon Go expanding to the east coast of the United States, into an area that will be a future casualty of a climate-change super storm. When people are destabilized to such an extent, these two examples will be indistinguishable.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p The maturation of facial recognition has a third, more insidious example of facilitating power. The world was captivated this year by ongoing ongoing protests in Hong Kong, with confronting images of anonymity in numbers against a total surveillance adversary. This is the true use case for biometrics, while we were busy arguing over representation, biometrics revealed itself to be a tool for facilitating power. Ethical and inclusive facial recognition criticism is a total failure, the only defence left is to physically tear it from the Earth.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p In 2018, researchers at Association for Computer Machinery produced a study that showed that explicitly instructing computer scientists to consider the organisation’s code of ethics had no observed effect when compared with a control group. That design ethics is so widely championed, means that we must urgently confront the reality that design Ethics and its tools are also deeply flawed, even if its goals are noble as reactions to shocking dystopias amplified by technology. Our lived experiences are at odds with how the tech we use is designed. 

     
  .lyt-row
    .lyt-txt.mcw-reg.ma-reg 
      p In almost all circumstances, from the social networks of today, to finance, ecological malpractice, polarization, surveillance and beyond, there are few examples where technology has created entirely new problems. Instead, technology is an accelerant for problems that are real and here. Digital infrastructure and products contribute scale, visibility and speed to the impact of these issues. Furthermore, our mobilisation amounts to a form of solutionism; a belief that small tweaks to existing practice should lead to “better” or “more ethical” outcomes. At a time of profound destabilisation, unchallenged practice and limited tools-based engagement may fix immediate problems, but allows them to re-emerge in new ways.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Let’s look at the tragedy of innocence. Despite fitting the narrative of tech addiction in small children, toddlers get attached to objects and will often throw wild tantrums when these objects are taken from them. Beyond that simple observation, maybe these sorts of images aren’t just examples of addictive interfaces, but symptom of familial fracture, of time-poor or overworked parents who rely on technology to stimulate their children.
  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p The tragedy of youth looks like social media causing addictive vanity.  But this frank testimony by a popular streamer suggests that this is a symptom of economic precarity, in which people with few skills are able to generate income as a sort of middle class celebrity, with little external support.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p It’s easy to dismiss the tragedy of reality as a bigoted crank, but this is absolutely understandable. But perhaps this is a symptom of broader social issues, tumbling and intertwining together, and emerging in twisted ways. The tragedy of reality lies in a collection of problems, social isolation, lack of mental health, and real or perceived fear of political processes.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p In each of these examples, technology is an accelerant of existing, desperate problems that cannot be solved alone with design ethics.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Moving from the present to the future, without more nuanced understanding of our work, we risk a repeat of the story of facial recognition.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p The Tesla Cybertruck is the latest in a competitive global effort to build innovative transport. Electric cars, often with autonomous driving technology, are seen as an inevitable reality, some predicting their deployment on public roads across the globe over the next ten years.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p In this video, a woman is hit and killed by an Uber autonomous vehicle. This horrific incident is described as a software malfunction, but it also reignited debate about the morality of software. Should a car choose to sacrifice one person over another in an emergency? It’s a serious and difficult question with ethical implications on societies: Cars alter entire landscapes and car infrastructure policies dramatically reshape cities. But autonomous cars are different. For the first time, cars must adapt to their environment through software decision making. This event and the following ethical debate catapulted the ethics of self driving cars into the public imagination.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p This is an extraordinary video of people attempting to escape the 2011 Tsunami in Japan by car. 

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg      
      p To date, there is little available research that examines or explains how a car might behave in a systemic catastrophe. 

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p We are on the precipice of a climate disaster, yet little public research exists that describes how a self driving car could navigate situations in which the environmental data cannot be acted upon autonomously. How does a car, trained on millions of hours of traffic data, respond to an ever-changing pathway of water and debris, or intense heat and falling, burning trees? In aeroplanes, fly-by-wire technologies disengage in an emergency, relying on the pilot to take over. It is likely that human driven cars offer the only chance of survival in a crisis.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p As this question looms, it is masked by discussions of software bugs and the machine’s moral compass. we are yet to even begin the discussion on the feasibility of this technology in an era of violent ecological collapse. The death of a cyclist is a symptom, a small representation of a looming systemic issue. The self driving car is borne from infrastructure that had significant impact on the climate, and we should be asking hard questions about this technology. Instead, we argue about the morality of a machine that may have no place in our world.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p Beyond the issues of youtube autoplay distracting kids from their homework, and boomer parents sharing conspiracies for likes on Facebook, the lived experiences and struggles of users is at odds both with how infrastructure is conceived and built, and how much importance we place on these outcomes themselves. As we begin this new, precarious decade, we must look at our work with the nuanced attention it deserves, as an accelerant that demands meaningful revision of practice to mitigate. Our work is part of a greater whole that amplifies - not causes - tremendous upheaval in our lives.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p All infrastructure is an expression of power.
      p Interfaces and technologies are social, political and ecological accelerants.
      p Solutionism at scale prevents true change.

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg      
      p From Decolonising privacy studies, to understanding design’s central marketisation of our lives, all practice is built on an unchallenged system whose foundations must be dismantled. 

  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p We must look beyond the limitations of design ethics and how the desire to practice seductive past and the future shows how design ethics helps to mask these trajectories. Only then will we be able to respond to our fullest potential and avert the darkest timeline. Design Ethics? No Thanks!
  .lyt-row
    .lyt-txt.mcw-reg.ma-reg
      p #[a(href="https://twitter.com/helveticade" target="_blank") Cade Diehm]
      p Winter 2020